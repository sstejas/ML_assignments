{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxmFK7zgX4B/Du6pXm89Ot"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["A2.\n"],"metadata":{"id":"FRNR38s9qNhJ"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SjbzfXYpoJg3","executionInfo":{"status":"ok","timestamp":1742660721061,"user_tz":-330,"elapsed":74969,"user":{"displayName":"Monkey.D Luffy","userId":"10844288319575730464"}},"outputId":"fbbe6e49-b4b8-490b-a5c3-10bfe8ce67a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-e403494107a1>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['Income'].fillna(df['Income'].median(), inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["Best Parameters: {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': True}\n","Best Score: 0.8805807566019824\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.impute import SimpleImputer\n","import numpy as np\n","\n","# Load dataset\n","df = pd.read_excel(\"/content/markrting campain.xlsx\")  # Update with actual file path\n","\n","# Handle missing values in 'Income'\n","df['Income'].fillna(df['Income'].median(), inplace=True)\n","\n","# Encode categorical variables\n","categorical_features = ['Education', 'Marital_Status']\n","df[categorical_features] = df[categorical_features].apply(LabelEncoder().fit_transform)\n","\n","# Define features and target\n","X = df.drop(columns=['ID', 'Dt_Customer', 'Response', 'Z_CostContact', 'Z_Revenue'])\n","y = df['Response']\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Define hyperparameter grid for RandomizedSearchCV\n","param_dist = {\n","    'n_estimators': [50, 100, 200, 300, 400],\n","    'max_depth': [10, 20, 30, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'bootstrap': [True, False]\n","}\n","\n","# Create Random Forest classifier\n","rf = RandomForestClassifier(random_state=42)\n","\n","# Perform RandomizedSearchCV\n","tuner = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=20, cv=5, n_jobs=-1, verbose=1, random_state=42)\n","tuner.fit(X_train, y_train)\n","\n","# Output best parameters and best score\n","print(\"Best Parameters:\", tuner.best_params_)\n","print(\"Best Score:\", tuner.best_score_)\n"]},{"cell_type":"markdown","source":["A3."],"metadata":{"id":"7Co2IPNZqr2S"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","from xgboost import XGBClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import numpy as np\n","\n","# Load dataset\n","df = pd.read_excel(\"/content/markrting campain.xlsx\")  # Update with actual file path\n","\n","# Handle missing values in 'Income'\n","df['Income'].fillna(df['Income'].median(), inplace=True)\n","\n","# Encode categorical variables\n","categorical_features = ['Education', 'Marital_Status']\n","df[categorical_features] = df[categorical_features].apply(LabelEncoder().fit_transform)\n","\n","# Define features and target\n","X = df.drop(columns=['ID', 'Dt_Customer', 'Response', 'Z_CostContact', 'Z_Revenue'])\n","y = df['Response']\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Define classifiers\n","classifiers = {\n","    \"Random Forest\": RandomForestClassifier(random_state=42),\n","    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n","    \"SVM\": SVC(random_state=42),\n","    \"Naïve Bayes\": GaussianNB(),\n","    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n","    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n","    \"MLP\": MLPClassifier(random_state=42)\n","}\n","\n","# Evaluate classifiers\n","results = []\n","for name, model in classifiers.items():\n","    model.fit(X_train, y_train)\n","    y_train_pred = model.predict(X_train)\n","    y_test_pred = model.predict(X_test)\n","\n","    results.append({\n","        \"Model\": name,\n","        \"Train Accuracy\": accuracy_score(y_train, y_train_pred),\n","        \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n","        \"Train Precision\": precision_score(y_train, y_train_pred),\n","        \"Test Precision\": precision_score(y_test, y_test_pred),\n","        \"Train Recall\": recall_score(y_train, y_train_pred),\n","        \"Test Recall\": recall_score(y_test, y_test_pred),\n","        \"Train F1 Score\": f1_score(y_train, y_train_pred),\n","        \"Test F1 Score\": f1_score(y_test, y_test_pred)\n","    })\n","\n","# Create a DataFrame for results\n","results_df = pd.DataFrame(results)\n","print(results_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3W6WKs3mqs3b","executionInfo":{"status":"ok","timestamp":1742660890544,"user_tz":-330,"elapsed":3785,"user":{"displayName":"Monkey.D Luffy","userId":"10844288319575730464"}},"outputId":"3e3b6b18-f5f4-4bbd-ed22-c2d3666a1081"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-247c888be0ae>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['Income'].fillna(df['Income'].median(), inplace=True)\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:28:14] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["           Model  Train Accuracy  Test Accuracy  Train Precision  \\\n","0  Random Forest        0.994978       0.881696         0.992366   \n","1  Decision Tree        0.994978       0.812500         1.000000   \n","2            SVM        0.851004       0.850446         0.000000   \n","3    Naïve Bayes        0.781250       0.774554         0.335092   \n","4        XGBoost        0.994420       0.868304         1.000000   \n","5       AdaBoost        0.889509       0.875000         0.725490   \n","6            MLP        0.851562       0.854911         0.513514   \n","\n","   Test Precision  Train Recall  Test Recall  Train F1 Score  Test F1 Score  \n","0        0.818182      0.973783     0.268657        0.982987       0.404494  \n","1        0.380282      0.966292     0.402985        0.982857       0.391304  \n","2        0.000000      0.000000     0.000000        0.000000       0.000000  \n","3        0.339623      0.475655     0.537313        0.393189       0.416185  \n","4        0.617647      0.962547     0.313433        0.980916       0.415842  \n","5        0.703704      0.415730     0.283582        0.528571       0.404255  \n","6        0.625000      0.071161     0.074627        0.125000       0.133333  \n"]}]}]}